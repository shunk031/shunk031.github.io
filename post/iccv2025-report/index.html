<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: February 11, 2026 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.7" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Fira+Sans:wght@300;800&family=Merriweather:wght@400;900&family=Permanent+Marker:wght@400&display=swap&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Fira+Sans:wght@300;800&family=Merriweather:wght@400;900&family=Permanent+Marker:wght@400&display=swap&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.db92ece0de614f1190233c6bd60e89d2.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" disabled>
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" >
  

  
  

  <meta name="google-site-verification" content="mlfhgZD5ToIaXCc4qjAka3OdD1xq0PguCaXpTv0VUYM" />





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114287158-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-114287158-2', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>
























  
  
  






  <meta name="author" content="ÂåóÁî∞ ‰øäËºî" />





  

<meta name="description" content="At ICCV 2025, our team from LY Corp. successfully organised and participated in a workshop and paper presentation, gaining deep insights into the shift of computer‚Äêvision research toward structured, controllable design generation and fast, reliable foundation-model technologies." />



<link rel="alternate" hreflang="en-us" href="https://shunk031.me/post/iccv2025-report/" />
<link rel="canonical" href="https://shunk031.me/post/iccv2025-report/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu10051210922980447289.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu9607046383224317331.png" />

<meta name="theme-color" content="#1565c0" />










  






<meta property="twitter:card" content="summary_large_image" />

  <meta property="twitter:site" content="@shunk031" />
  <meta property="twitter:creator" content="@shunk031" />
<meta property="twitter:image" content="https://shunk031.me/post/iccv2025-report/featured.webp" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="shunk031.me" />
<meta property="og:url" content="https://shunk031.me/post/iccv2025-report/" />
<meta property="og:title" content="ICCV2025 Conference Participation Report | shunk031.me" />
<meta property="og:description" content="At ICCV 2025, our team from LY Corp. successfully organised and participated in a workshop and paper presentation, gaining deep insights into the shift of computer‚Äêvision research toward structured, controllable design generation and fast, reliable foundation-model technologies." /><meta property="og:image" content="https://shunk031.me/post/iccv2025-report/featured.webp" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2025-11-25T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2026-02-11T13:26:19&#43;09:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://shunk031.me/post/iccv2025-report/"
  },
  "headline": "ICCV2025 Conference Participation Report",
  
  "image": [
    "https://shunk031.me/post/iccv2025-report/featured.webp"
  ],
  
  "datePublished": "2025-11-25T00:00:00Z",
  "dateModified": "2026-02-11T13:26:19+09:00",
  
  "author": {
    "@type": "Person",
    "name": "Shunsuke Kitada, Ph.D."
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "shunk031.me",
    "logo": {
      "@type": "ImageObject",
      "url": "https://shunk031.me/media/icon_hu8917630770089639356.png"
    }
  },
  "description": "At ICCV 2025, our team from LY Corp. successfully organised and participated in a workshop and paper presentation, gaining deep insights into the shift of computer‚Äêvision research toward structured, controllable design generation and fast, reliable foundation-model technologies."
}
</script>

  

  




  
  
  

  
  

  


  
  <title>ICCV2025 Conference Participation Report | shunk031.me</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper  dark " data-wc-page-id="b57666e3212bce16b70a9af1b45e3a83" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.db21e13b9b5c4f4b947717750ec8b3cc.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">shunk031.me</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">shunk031.me</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>üè† Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#recent-news"><span>üóûÔ∏è News</span></a>
          </li>

          
          

          
          <li class="nav-item dropdown">
            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true"><span>üìù Publications</span><span class="caret"></span>
            </a>
            <div class="dropdown-menu">
              
                <a class="dropdown-item" href="/#journal-articles"><span>Journal Article</span></a>
              
                <a class="dropdown-item" href="/#conference-papers"><span>Conference Paper</span></a>
              
                <a class="dropdown-item" href="/#preprints"><span>Preprint</span></a>
              
                <a class="dropdown-item" href="/#dissertation"><span>Thesis</span></a>
              
                <a class="dropdown-item" href="/#domestic-conferences"><span>Domestic Conference Paper / Presentation</span></a>
              
            </div>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#talks"><span>üéôÔ∏è Talks</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#awards-and-grants"><span>üèÜ Awards & Grants</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#featured-posts"><span>üìù Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#experience"><span>üíª Experience</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="https://twitter.com/shunk031" data-toggle="tooltip" data-placement="bottom" title="Follow me on Twitter" target="_blank" rel="noopener" aria-label="Follow me on Twitter">
                <i class="fab fa-twitter" aria-hidden="true"></i>
              </a>
            </li>
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  






















  
  



<div class="article-container pt-3">
  <h1>ICCV2025 Conference Participation Report</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      <a href="/authors/shunsuke-kitada/">Shunsuke Kitada, Ph.D.</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Feb 11, 2026
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/tech-blog/">Tech Blog</a>, <a href="/category/conference-report/">Conference Report</a></span>
  

</div>

  





</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 377px;">
  <div style="position: relative">
    <img src="/post/iccv2025-report/featured_hu7606488747241117255.webp" width="720" height="377" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      <h1 id="our-paper-and-workshop-accepted-at-iccv-2025-the-top-international-conference-on-computer-vision-participation-report">Our Paper and Workshop Accepted at ICCV 2025, the Top International Conference on Computer Vision (Participation Report)</h1>
<p>Hello, I‚Äôm <a href="https://shunk031.me/" target="_blank" rel="noopener">Shunsuke Kitada</a> (<a href="https://x.com/shunk031" target="_blank" rel="noopener">@shunk031</a>), and I work at LY Corporation on research and development for image generation and design generation.<br>
From October 19 to 23, 2025, I attended and presented at the <a href="https://iccv.thecvf.com/Conferences/2025" target="_blank" rel="noopener">International Conference on Computer Vision, ICCV 2025</a>, held in Hawaii, USA.</p>
<p>In this article, I‚Äôll share insights gained from ICCV workshops and the main conference. First, I‚Äôll report on the workshop we organized, where I and other LY employees led international discussions, and introduce the insights gained from a workshop specialized in advertising and design generation. Then, I‚Äôll analyze the latest trends at the main conference‚Äîsuch as acceleration and controllability of diffusion models, and hierarchical / structured design generation‚Äîalongside an overview of our own research team‚Äôs presentation.</p>


















<figure  id="figure-entrance-of-the-venue">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="Entrance of the venue" srcset="
               /post/iccv2025-report/iccv2025_aloha_hu9205790033709921788.webp 400w,
               /post/iccv2025-report/iccv2025_aloha_hu3523069546937835175.webp 760w,
               /post/iccv2025-report/iccv2025_aloha_hu6346094133337153546.webp 1200w"
               src="/post/iccv2025-report/iccv2025_aloha_hu9205790033709921788.webp"
               width="760"
               height="573"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Entrance of the venue
    </figcaption></figure>

<p>This article is an English translation of the following Japanese article:
<div class="blogcard">
    <iframe class="hatenablogcard" style="width:100%;height:155px;max-width:500px;"
        src="https://hatenablog-parts.com/embed?url=https%3a%2f%2ftechblog.lycorp.co.jp%2fja%2f20251125b" width="300" height="150" frameborder="0"
        scrolling="no"></iframe>
</div>
</p>
<h2 id="report-on-the-found-workshop">Report on the FOUND Workshop</h2>
<h3 id="workshop-overview-and-activities-as-organizers">Workshop Overview and Activities as Organizers</h3>
<p>Our workshop, titled <a href="https://iccv2025-found-workshop.limitlab.xyz/" target="_blank" rel="noopener">Foundation Data for Vision: Challenges and Opportunities (FOUND)</a>, was organized by LY employees including myself (Kitada) and <a href="https://scholar.google.com/citations?user=o2lMlxMAAAAJ" target="_blank" rel="noopener">Dr. Komatsu</a>, and was accepted at ICCV 2025.</p>


















<figure  id="figure-our-companys-news-page-about-the-workshop-acceptance">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><a href="https://research.lycorp.co.jp/jp/news/329"  target="_blank" rel="noopener"><img alt="Our company‚Äôs news page about the workshop acceptance" srcset="
               /post/iccv2025-report/iccv2025_found-workshop_accepted_hu8037479907825113008.webp 400w,
               /post/iccv2025-report/iccv2025_found-workshop_accepted_hu14362133551314700383.webp 760w,
               /post/iccv2025-report/iccv2025_found-workshop_accepted_hu2973513948187227158.webp 1200w"
               src="/post/iccv2025-report/iccv2025_found-workshop_accepted_hu8037479907825113008.webp"
               width="760"
               height="491"
               loading="lazy" /></a></div>
  </div><figcaption>
      Our company‚Äôs news page about the workshop acceptance
    </figcaption></figure>



















<figure  id="figure-found-workshop-homepage">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><a href="https://iccv2025-found-workshop.limitlab.xyz/"  target="_blank" rel="noopener"><img alt="FOUND workshop homepage" srcset="
               /post/iccv2025-report/iccv2025_found-workshop_hu15824662521425484324.webp 400w,
               /post/iccv2025-report/iccv2025_found-workshop_hu16844954075200301256.webp 760w,
               /post/iccv2025-report/iccv2025_found-workshop_hu13114132858030843862.webp 1200w"
               src="/post/iccv2025-report/iccv2025_found-workshop_hu15824662521425484324.webp"
               width="760"
               height="485"
               loading="lazy" /></a></div>
  </div><figcaption>
      FOUND workshop homepage
    </figcaption></figure>

<p>The theme centers on ‚Äúdata,‚Äù which is indispensable for recent advances in foundation models, and the workshop aimed to provide an international forum to discuss the challenges and opportunities around it.</p>
<p>This acceptance represents one of the rare cases where a workshop at ICCV, one of the world‚Äôs top-tier conferences, is led by Japanese researchers. It demonstrates that research and industrial efforts originating in Japan are being recognized on a global stage.</p>
<h3 id="lys-contribution-and-on-site-highlights">LY‚Äôs Contribution and On-Site Highlights</h3>
<p>LY Corporation took the lead in organizing this workshop. Through this, we were able to demonstrate, at least to some extent, that we are in a position to drive international discussions on <em>foundation data</em>, an urgent topic that will shape the future of the computer vision field.</p>


















<figure  id="figure-found-workshop-opening-opening-session-by-lead-organizer-yoshihiro-fukuharahttpsgathelucknethome">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="FOUND workshop opening." srcset="
               /post/iccv2025-report/iccv2025_found-workshop_opening_hu8480770892095190044.webp 400w,
               /post/iccv2025-report/iccv2025_found-workshop_opening_hu4274237585929242566.webp 760w,
               /post/iccv2025-report/iccv2025_found-workshop_opening_hu6146468951651122439.webp 1200w"
               src="/post/iccv2025-report/iccv2025_found-workshop_opening_hu8480770892095190044.webp"
               width="760"
               height="573"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      FOUND workshop opening. Opening session by lead organizer <a href="https://gatheluck.net/home/" target="_blank" rel="noopener">Yoshihiro Fukuhara</a>.
    </figcaption></figure>



















<figure  id="figure-found-workshop-sponsors-ly-corporation-line„É§„Éï„Éº-was-also-listed-as-a-sponsor">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="FOUND workshop sponsors." srcset="
               /post/iccv2025-report/iccv2025_found-workshop_sponsors_hu1762683740026704632.webp 400w,
               /post/iccv2025-report/iccv2025_found-workshop_sponsors_hu640212202541000365.webp 760w,
               /post/iccv2025-report/iccv2025_found-workshop_sponsors_hu2344867604703243204.webp 1200w"
               src="/post/iccv2025-report/iccv2025_found-workshop_sponsors_hu1762683740026704632.webp"
               width="760"
               height="573"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      FOUND workshop sponsors. LY Corporation (LINE„É§„Éï„Éº) was also listed as a sponsor.
    </figcaption></figure>

<p>The workshop attracted many researchers and practitioners from both academia and industry, leading to lively technical exchanges. In particular, the joint social event we held together with the <a href="https://iccv2025-limit-workshop.limitlab.xyz/" target="_blank" rel="noopener">LIMIT Workshop</a>, also at ICCV 2025, was extremely successful. It served as a valuable opportunity to foster deeper networking among participants and to expand the possibilities for future international collaborations.</p>


















<figure  id="figure-limit--found-workshop-banquet--researchers-from-google-openai-salesforce-research-who-gave-invited-talks-at-the-workshops-as-well-as-many-members-from-universities-and-research-institutions-joined-us">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="LIMIT &amp; FOUND workshop banquet" srcset="
               /post/iccv2025-report/iccv2025_limit-found-workshop_banquet_hu6443715659232877090.webp 400w,
               /post/iccv2025-report/iccv2025_limit-found-workshop_banquet_hu1415703980639316576.webp 760w,
               /post/iccv2025-report/iccv2025_limit-found-workshop_banquet_hu7771702000750139216.webp 1200w"
               src="/post/iccv2025-report/iccv2025_limit-found-workshop_banquet_hu6443715659232877090.webp"
               width="760"
               height="573"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      LIMIT &amp; FOUND workshop banquet. . Researchers from Google, OpenAI, Salesforce Research, who gave invited talks at the workshops, as well as many members from universities and research institutions joined us.
    </figcaption></figure>

<p>Based on this experience as organizers, if you are considering hosting a workshop at an international conference, or if you feel uncertain about how to write a proposal or how to manage operations, please feel free to reach out. In particular, <a href="https://gatheluck.net/home/" target="_blank" rel="noopener">Mr. Fukuhara</a>, who served as the lead organizer, and <a href="https://hirokatsukataoka.net/" target="_blank" rel="noopener">Dr. Kataoka</a> from AIST, who led the co-hosted LIMIT Workshop, both have extensive experience and can provide concrete advice. I (<a href="https://shunk031.me" target="_blank" rel="noopener">Kitada</a>) would also be happy to support where I can. I sincerely hope that more researchers and engineers from Japan will take the lead in discussions at international conferences.</p>
<h2 id="insights-from-attended-workshops">Insights from Attended Workshops</h2>
<p>From the perspective of my domain of responsibility and expertise‚Äîimage generation, design generation, and business impact (especially in advertising and marketing), I attended and will report on two workshops.</p>
<h3 id="report-on-computer-vision-in-advertising-and-marketing-cvam">Report on ‚ÄúComputer Vision in Advertising and Marketing (CVAM)‚Äù</h3>
<p>The <a href="https://cvam-workshop.github.io/" target="_blank" rel="noopener">CVAM Workshop</a> focused on the latest applications of computer vision (CV) in the fields of digital advertising and marketing.</p>


















<figure  id="figure-cvam-workshop-page">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><a href="https://cvam-workshop.github.io/"  target="_blank" rel="noopener"><img alt="CVAM workshop page" srcset="
               /post/iccv2025-report/iccv2025_cvam-workshop_hu5458789903910746368.webp 400w,
               /post/iccv2025-report/iccv2025_cvam-workshop_hu3825388159096124272.webp 760w,
               /post/iccv2025-report/iccv2025_cvam-workshop_hu13606796695937814031.webp 1200w"
               src="/post/iccv2025-report/iccv2025_cvam-workshop_hu5458789903910746368.webp"
               width="760"
               height="491"
               loading="lazy" /></a></div>
  </div><figcaption>
      CVAM workshop page
    </figcaption></figure>

<p>From a business impact standpoint, the workshop‚Äôs theme, applications of CV technologies in advertising and marketing, specifically covered creative generation, optimization of marketing systems, brand intelligence, and more.</p>
<p>In our business, which aims to maximize advertising effectiveness, understanding and generating visual content is an urgent challenge. By participating in CVAM, I was able to reconfirm the importance of discussions on how to connect the latest image generation technologies not only to creative production, but also to ad effectiveness measurement and prediction of consumer behavior.</p>
<h3 id="report-on-workshop-on-graphic-design-understanding-and-generation-2025-gdug">Report on ‚ÄúWorkshop on Graphic Design Understanding and Generation 2025 (GDUG)‚Äù</h3>
<p>The <a href="https://sites.google.com/view/gdug-workshop" target="_blank" rel="noopener">GDUG Workshop</a> aimed to discuss key concepts, technical constraints, and ethical aspects in the recognition and generation of graphic design and documents.</p>


















<figure  id="figure-gdug-workshop-page">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><a href="https://sites.google.com/view/gdug-workshop"  target="_blank" rel="noopener"><img alt="GDUG workshop page" srcset="
               /post/iccv2025-report/iccv2025_gdug-workshop_hu7554105050009292329.webp 400w,
               /post/iccv2025-report/iccv2025_gdug-workshop_hu9736956839242095694.webp 760w,
               /post/iccv2025-report/iccv2025_gdug-workshop_hu1840477856031997629.webp 1200w"
               src="/post/iccv2025-report/iccv2025_gdug-workshop_hu7554105050009292329.webp"
               width="760"
               height="491"
               loading="lazy" /></a></div>
  </div><figcaption>
      GDUG workshop page
    </figcaption></figure>

<p>From the perspective of design generation, a shared concern was that, while many research efforts focus on pixel-based image generation, real-world design workflows‚Äîsuch as creating posters, online ads, and websites‚Äîare based on structured documents (e.g., layered object representations, style attributes, typography) rather than raw pixels. This gap between research and practice was repeatedly highlighted.</p>
<p>In the invited talks, cutting-edge methods for layer decomposition were introduced, where existing designs are decomposed into native layers such as text, foreground elements, and background (e.g., the <a href="https://arxiv.org/abs/2507.05601" target="_blank" rel="noopener">Accordion pipeline</a>).<br>
This clearly showed that design generation is evolving from simply producing a ‚Äúflat, single-layer output‚Äù toward handling layered structures similar to those used in real-world design processes. It also provided important hints for rethinking the direction of our own design generation technology development.</p>
<h2 id="main-conference-report-and-key-trend-analysis">Main Conference Report and Key Trend Analysis</h2>
<h3 id="overall-statistics-and-scale-of-iccv-2025">Overall Statistics and Scale of ICCV 2025</h3>
<p>ICCV 2025 was held at the <a href="https://www.meethawaii.com/convention-center/" target="_blank" rel="noopener">Hawaii Convention Center</a>, with nearly 7,000 participants. Over 11,000 papers were submitted, of which around 2,600 were accepted (an acceptance rate of about 24%).</p>
<p>The top three research trends were: generative AI (images and videos), 3D processing from multi-view / multi-sensor data, and multimodal learning. In particular, in the generative model area, I felt that a major trend is the shift from <em>diffusion</em> models to <em>flow</em> models.<br>
For a more detailed overview and analysis of trends, I recommend the <a href="https://hirokatsukataoka.net/temp/presen/251031ICCV2025Report_FinalizedVer.pdf" target="_blank" rel="noopener">ICCV 2025 Report</a> compiled by volunteers from <a href="https://xpaperchallenge.org/cv/" target="_blank" rel="noopener">cvpaper.challenge</a>.</p>


















<figure  id="figure-iccv-2025-venue-guide-posted-inside-the-hawaii-convention-center">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="ICCV 2025 venue guide posted inside the Hawaii Convention Center" srcset="
               /post/iccv2025-report/iccv2025_hawaiiconvention_hu11828663015799367673.webp 400w,
               /post/iccv2025-report/iccv2025_hawaiiconvention_hu3381625455914555934.webp 760w,
               /post/iccv2025-report/iccv2025_hawaiiconvention_hu1950881321459719251.webp 1200w"
               src="/post/iccv2025-report/iccv2025_hawaiiconvention_hu11828663015799367673.webp"
               width="760"
               height="573"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      ICCV 2025 venue guide posted inside the Hawaii Convention Center
    </figcaption></figure>

<h3 id="introduction-of-our-research-teams-presentation-pino">Introduction of Our Research Team‚Äôs Presentation ‚ÄúPINO‚Äù</h3>
<p>Our research presentation <a href="https://arxiv.org/abs/2507.19292" target="_blank" rel="noopener">PINO (Person-Interaction Noise Optimization)</a> is a technique that enables long-duration, customizable, arbitrary-size group motion generation.
This research is the result of our summer internship program, led primarily by <a href="https://sinc865.github.io/" target="_blank" rel="noopener">Mr. Ota</a> from Tokyo Institute of Technology.</p>


















<figure  id="figure-our-research-scientists-dr-yuhttpsyu1utcom-left-and-dr-fujiwarahttpskfworkscom-right-presenting-the-poster-yu-was-also-selected-as-an-outstanding-reviewer-for-the-main-conference">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="PINO poster session" srcset="
               /post/iccv2025-report/iccv2025_pino_hu17782557251613721486.webp 400w,
               /post/iccv2025-report/iccv2025_pino_hu1892567959345893049.webp 760w,
               /post/iccv2025-report/iccv2025_pino_hu3578787767395407793.webp 1200w"
               src="/post/iccv2025-report/iccv2025_pino_hu17782557251613721486.webp"
               width="760"
               height="573"
               loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Our research scientists <a href="https://yu1ut.com/" target="_blank" rel="noopener">Dr. Yu</a> (left) and <a href="https://kfworks.com/" target="_blank" rel="noopener">Dr. Fujiwara</a> (right) presenting the poster. Yu was also selected as an Outstanding Reviewer for the main conference.
    </figcaption></figure>

<p>In terms of the overview and contributions of PINO, the method employs a unique approach that optimizes the noise input when denoising motion sequences using a base diffusion model (e.g., <a href="https://arxiv.org/abs/2304.05684" target="_blank" rel="noopener">InterGen</a>).</p>


















<figure  id="figure-figure-from-pino-ota-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2507.19292v1/x1.png" alt="PINO 1" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from PINO [Ota+ ICCV‚Äô25]
    </figcaption></figure>

<p>By this optimization, the generated motions are not only aligned with the text prompts, but also enforced to be physically plausible through cost terms that reduce physical artifacts such as body intersections and penetrations.</p>


















<figure  id="figure-figure-from-pino-ota-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2507.19292v1/x2.png" alt="PINO 2" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from PINO [Ota+ ICCV‚Äô25]
    </figcaption></figure>

<p>Furthermore, users can control root positions, regions, and directions via penalty terms, enabling customizable motion generation.</p>
<h3 id="notable-technical-trends-in-image--design-generation">Notable Technical Trends in Image &amp; Design Generation</h3>
<p>From the standpoint of my work in image and design generation, I‚Äôll analyze the key trends observed at the main conference, including their potential for business impact.</p>
<h4 id="efficiency-and-reliability-of-diffusion-models-the-superiority-of-flow-models">Efficiency and Reliability of Diffusion Models: The Superiority of Flow Models</h4>
<p>The evolution of diffusion models (DMs) is shifting focus from mere realism to speed, controllability, and reliability.</p>
<p>Regarding flow-based generation and fast sampling, Flow Matching models are gaining prominence as a training paradigm for generative models. In particular, <a href="https://arxiv.org/abs/2506.05350" target="_blank" rel="noopener">Contrastive Flow Matching</a> maximizes the dissimilarity between the estimated flow and an independently sampled flow, thereby consistently outperforming previous Flow Matching methods (better FID scores) and enabling high-quality, fast generation.</p>


















<figure  id="figure-figure-from-contrastive-flow-matching-stoica-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2506.05350v1/extracted/6514412/figures/imgs/flows.png" alt="Figure from [Stoica&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from Contrastive Flow Matching [Stoica+ ICCV‚Äô25]
    </figcaption></figure>

<p>For inversion-free editing, <a href="https://arxiv.org/abs/2412.08629" target="_blank" rel="noopener">FlowEdit</a> utilizes pretrained flow models (SD3, FLUX.1, etc.) and removes the need for an ‚Äúinversion‚Äù step during editing, instead tracing a shorter, more direct path from the source image distribution to the target distribution. This achieves high text alignment and strong structural preservation (excellent LPIPS), and FlowEdit received the Best Student Paper Award.</p>


















<figure  id="figure-figure-from-flowedit-kulikov-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2412.08629v2/x2.png" alt="Figure from FlowEdit [Kulikov&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from FlowEdit [Kulikov+ ICCV‚Äô25]
    </figcaption></figure>

<p>In controllable generation (<a href="https://arxiv.org/abs/2412.00100" target="_blank" rel="noopener">FlowChef</a>), Rectified Flow Models (RFMs) are leveraged, where sampling trajectories become nearly straight and the nonlinear error term approaches zero. By skipping gradient computation (Gradient Skipping), FlowChef achieves deterministic and efficient controllable generation for tasks such as inpainting and super-resolution‚Äîwithout additional training or large-scale backpropagation.</p>


















<figure  id="figure-figure-from-flowchef-patel-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2412.00100v1/x2.png" alt="Figure from FlowChef [Patel&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from FlowChef [Patel+ ICCV‚Äô25]
    </figcaption></figure>

<h4 id="evaluating-and-improving-generation-quality-human-centered-approaches">Evaluating and Improving Generation Quality (Human-Centered Approaches)</h4>
<p>As a method for optimizing image generation based on human preferences, an evaluation model (HPSv3) was proposed and built using a large and diverse dataset (<a href="https://arxiv.org/abs/2508.03789" target="_blank" rel="noopener">HPDv3</a>: 1.08 million text‚Äìimage pairs) combined with an uncertainty-aware ranking loss. This enables Model-wise Preference (selecting the optimal model for a given prompt) and Sample-wise Preference (selecting the best sample among multiple generations).</p>


















<figure  id="figure-figure-from-hpsv3-ma-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2508.03789v2/x1.png" alt="Figure from HPSv3 [Ma&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from HPSv3 [Ma+ ICCV‚Äô25]
    </figcaption></figure>

<p>The self-reflection‚Äìdriven iterative improvement approach (<a href="https://arxiv.org/abs/2504.16080" target="_blank" rel="noopener">Reflection Tuning</a>) proposes a paradigm in which a reward model or multimodal LLM (MLLM) generates ‚Äúreflection‚Äù prompts that describe the shortcomings of a generated image in text, and the image is then iteratively improved according to these instructions. This allows targeted corrections such as ‚Äúremove the sunlight‚Äù or ‚Äúchange the clothes.‚Äù</p>


















<figure  id="figure-figure-from-reflection-tuning-zhou-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2504.16080v1/x1.png" alt="Figure from Reflection Tuning [Zhou&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from Reflection Tuning [Zhou+ ICCV‚Äô25]
    </figcaption></figure>

<h4 id="structured-generation-to-accelerate-design-and-advertising-applications">Structured Generation to Accelerate Design and Advertising Applications</h4>
<p>For layer-based structured generation, <a href="https://arxiv.org/abs/2503.12838" target="_blank" rel="noopener">DreamLayer</a> addresses the long-standing challenge of ‚Äúlayer consistency‚Äù in design generation by generating multiple transparent image layers simultaneously in a coherent manner. It uses mechanisms such as Layer-Shared Self-Attention to resolve inconsistencies in occlusion relationships and spatial layout between foreground and background.</p>


















<figure  id="figure-figure-from-dreamlayer-huang-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2503.12838v1/x1.png" alt="Figure from DreamLayer [Huang&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from DreamLayer [Huang+ ICCV‚Äô25]
    </figcaption></figure>

<p>Regarding advances in layout control, <a href="https://arxiv.org/abs/2412.03859" target="_blank" rel="noopener">CreatiLayout</a> (SiamLayout) is a Transformer-based model that generates images from layout (placement information) and demonstrates high performance in spatial consistency, color, shape, and more. Its LayoutDesigner component achieves state-of-the-art accuracy in layout planning tasks, surpassing GPT-4 Turbo.</p>


















<figure  id="figure-figure-from-creatilayout-zhang-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2412.03859v3/x2.png" alt="Figure from CreatiLayout [Zhang&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from CreatiLayout [Zhang+ ICCV‚Äô25]
    </figcaption></figure>

<p>For high-fidelity image compositing, <a href="https://arxiv.org/abs/2504.08291" target="_blank" rel="noopener">DreamFuse</a> proposes a new method called Localized DPO (Localized Direct Preference Optimization) to better fuse foreground and background images in a way that humans prefer. By learning to avoid trivial ‚Äúcopy-and-paste‚Äù images (negative samples), the model more appropriately handles fusion-related transformations‚Äîsuch as perspective and affine transformations‚Äîleading to improved background consistency and harmony with the foreground.</p>


















<figure  id="figure-figure-from-dreamfuse-huang-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2504.08291v1/x1.png" alt="Figure from DreamFuse [Huang&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from DreamFuse [Huang+ ICCV‚Äô25]
    </figcaption></figure>

<p>For accurate visual text synthesis, <a href="https://arxiv.org/abs/2507.00992" target="_blank" rel="noopener">UniGlyph</a> uses segmentation masks at the pixel level as conditions in a diffusion-based framework, addressing problems such as blurry glyphs and style inconsistencies. It shows strong performance especially for rendering small text and complex layouts.</p>


















<figure  id="figure-figure-from-uniglyph-wang-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2507.00992v2/x1.png" alt="Figure from UniGlyph [Wang&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from UniGlyph [Wang+ ICCV‚Äô25]
    </figcaption></figure>

<p><a href="https://arxiv.org/abs/2410.09879" target="_blank" rel="noopener">TextMaster</a> is a unified framework that controls both text glyphs and styles. By integrating OCR techniques to compute L2 losses on character features, it enables realistic text editing.</p>


















<figure  id="figure-figure-from-textmaster-yan-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2410.09879v2/x3.png" alt="Figure from TextMaster [Yan&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from TextMaster [Yan+ ICCV‚Äô25]
    </figcaption></figure>

<p>For deployment in advertising and marketing, the gaze prediction method <a href="https://arxiv.org/abs/2507.23021" target="_blank" rel="noopener">ScanDiff</a> proposes using diffusion models to predict scanpaths (gaze trajectories) in response to visual stimuli such as ads. It achieves high performance on datasets like COCO-Search18. This is an important technology for modeling human attention, crucial to optimizing the visibility and effectiveness of ad creatives.</p>


















<figure  id="figure-figure-from-scandiff-cartella-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2507.23021v1/x2.png" alt="Figure from ScanDiff [Cartella&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from ScanDiff [Cartella+ ICCV‚Äô25]
    </figcaption></figure>

<p>A new research theme, understanding advertising videos, has also been proposed with <a href="https://arxiv.org/abs/2509.08621" target="_blank" rel="noopener">AdsQA</a>, a QA benchmark for video understanding that incorporates challenges unique to ad videos. In this area, issues such as the sensitivity of reinforcement learning methods to data quality and the effects of prompt templates on performance are also analyzed.</p>


















<figure  id="figure-figure-from-adsqa-long-iccv25">
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="https://arxiv.org/html/2509.08621v1/x1.png" alt="Figure from AdsQA [Long&#43; ICCV‚Äô25]" loading="lazy" data-zoomable /></div>
  </div><figcaption>
      Figure from AdsQA [Long+ ICCV‚Äô25]
    </figcaption></figure>

<h2 id="conclusion">Conclusion</h2>
<p>Through my participation in ICCV 2025, I strongly realized that the computer vision field, especially image and design generation, has entered a phase where the focus has shifted from merely pursuing realism to emphasizing the ‚Äúpracticality and controllability‚Äù of the technology.</p>
<p>The trends observed in the workshops and main conference clearly show that generative AI is evolving from pixel-based outputs to the generation of hierarchical and structured design elements that align closely with real design workflows. At the same time, advances in flow models are enabling fast and accurate generation and editing. This will be a key driver in revolutionizing the PDCA cycle for creatives in advertising and marketing applications.</p>
<p>LY Corporation will continue to fulfill its responsibility in governing foundation data and leading international discussions, while proactively applying these cutting-edge generation and control technologies to our business. Through this, we aim to establish a strong technological competitive advantage and contribute to society.</p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/iccv2025/">ICCV2025</a>
  
  <a class="badge badge-light" href="/tag/conference-report/">Conference Report</a>
  
  <a class="badge badge-light" href="/tag/computer-vision/">Computer Vision</a>
  
  <a class="badge badge-light" href="/tag/design-generation/">Design Generation</a>
  
  <a class="badge badge-light" href="/tag/foundation-models/">Foundation Models</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fshunk031.me%2Fpost%2Ficcv2025-report%2F&amp;text=ICCV2025&#43;Conference&#43;Participation&#43;Report" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fshunk031.me%2Fpost%2Ficcv2025-report%2F&amp;t=ICCV2025&#43;Conference&#43;Participation&#43;Report" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=ICCV2025%20Conference%20Participation%20Report&amp;body=https%3A%2F%2Fshunk031.me%2Fpost%2Ficcv2025-report%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fshunk031.me%2Fpost%2Ficcv2025-report%2F&amp;title=ICCV2025&#43;Conference&#43;Participation&#43;Report" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=ICCV2025&#43;Conference&#43;Participation&#43;Report%20https%3A%2F%2Fshunk031.me%2Fpost%2Ficcv2025-report%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      <a href="https://shunk031.me/"><img class="avatar mr-3 avatar-circle" src="https://s.gravatar.com/avatar/5bea5748e87ba7a12c2f4a8595672366?s=200" alt="Shunsuke Kitada, Ph.D."></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://shunk031.me/">Shunsuke Kitada, Ph.D.</a></h5>
      <h6 class="card-subtitle">Research Scientist working on Vision &amp; Language with Deep Learning</h6>
      <p class="card-text">My research interests include deep learning-based natural language processing, computer vision, medical image processing, and computational advertising.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/shunk031" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.facebook.com/shunk031" target="_blank" rel="noopener">
        <i class="fab fa-facebook"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=GUzGhQIAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/shunk031" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/shunk031/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://shunk031.hatenablog.com/" target="_blank" rel="noopener">
        <i class="fas fa-pen-nib"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://speakerdeck.com/shunk031" target="_blank" rel="noopener">
        <i class="fab fa-speaker-deck"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://www.researchgate.net/profile/Shunsuke_Kitada" target="_blank" rel="noopener">
        <i class="ai ai-researchgate"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/shunk031/cv/releases/latest/download/cv.pdf" target="_blank" rel="noopener">
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">
    

    <p class="powered-by">
        
        Hosted on <a href="https://github.com/shunk031/shunk031.github.io">GitHub</a> <i class="fab fa-github"></i>
    </p>

    
    






  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    Copyright ¬© 2026 Shunsuke Kitada. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>




    <p class="powered-by">
        
        
        
        Published with
        <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> ‚Äî
        the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">
            open source</a> website builder that empowers creators.
        
    </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.50933d940896e49f984a778650d5f7f5.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.7f5ebaff62ae468cff8bb3dd1337bb9b.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js" type="module"></script>


















</body>
</html>
